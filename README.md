# ğŸ‘ï¸â€ğŸ—¨ï¸ Computer Vision Projects Collection

This repository contains a suite of Computer Vision applications built using **TensorFlow**, **CNNs**, **OpenCV**, and **MediaPipe**. Each project demonstrates a unique use-case of real-time image processing and deep learning.

---

## ğŸ“¦ Projects Included

### 1. ğŸ¤Ÿ ASL Detection (American Sign Language)
- Detects and classifies ASL gestures from live webcam input.
- Built using a CNN model trained on ASL hand signs.
- Uses MediaPipe for efficient hand tracking.

### 2. ğŸ˜€ Emotion Detection
- Real-time facial emotion recognition (happy, sad, angry, etc.)
- Powered by OpenCV for face detection and a trained CNN for classification.
- Supports webcam-based live prediction.

### 3. âœ Gesture-Based Writing System
- Write characters on screen using hand gestures.
- MediaPipe tracks hand movement and OpenCV visualizes strokes.
- Can recognize and translate shapes to text with classification logic.

### 4. ğŸ–± Gesture-Based Mouse Control
- Control cursor and click using hand gestures.
- Includes features like:
  - Cursor movement
  - Click gestures
  - Scroll gestures
- Built with MediaPipe + pyautogui for mouse simulation.

### 5. ğŸ”Š Gesture-Based Volume Controller
- Adjust system volume using hand distance.
- Thumb and index finger pinch controls volume level in real-time.
- Requires `pycaw` (Windows) for volume manipulation.

### 6. ğŸ§‘â€ğŸ’¼ AI-Based Attendance System
- Face recognition-based attendance marking.
- Recognizes faces from a pre-trained dataset.
- Logs attendance with date & time into a CSV file.

---

## ğŸ› ï¸ Tech Stack

- **Languages:** Python
- **Libraries & Tools:**
  - `TensorFlow`, `Keras` â€” Deep Learning models
  - `OpenCV` â€” Image processing
  - `MediaPipe` â€” Hand/Face tracking
  - `pyautogui`, `pycaw` â€” System-level interactions
  - `numpy`, `pandas`, `matplotlib` â€” Data handling and visualization


